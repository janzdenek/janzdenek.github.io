[{"authors":["admin"],"categories":null,"content":"Jan is a third-year Ph.D. student in information science and technology particularly interested in artificial intelligence, computer vision, and machine learning. He is a member of the Machine Perception Group (Nakayama Laboratory) at the University of Tokyo, which he joined in 2015. Before commencing his graduate studies at the University of Tokyo, he earned his bachelor\u0026rsquo;s degree in computer and information science at the Czech Technical University in Prague, Czech Republic, where he was born and grew up.\nHis research focuses on computer vision, in particular on image generation and text in natural scene images. Recently, he has been interested in application of generative adversarial networks for handwritten text and text in natural scene images.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://janzdenek.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Jan is a third-year Ph.D. student in information science and technology particularly interested in artificial intelligence, computer vision, and machine learning. He is a member of the Machine Perception Group (Nakayama Laboratory) at the University of Tokyo, which he joined in 2015. Before commencing his graduate studies at the University of Tokyo, he earned his bachelor\u0026rsquo;s degree in computer and information science at the Czech Technical University in Prague, Czech Republic, where he was born and grew up.","tags":null,"title":"Jan Zdenek","type":"authors"},{"authors":null,"categories":null,"content":"現在、ACM Multimedia 2021で手書き文字の画像生成の論文が査読中です。この論文では手書き文字の画像生成のための新しい手法を提案しています。\n手書き文字画像生成の既存のstate-of-the-art手法のモデルは多くのメモリーを必要として非常に非効率的です。さらに、必要なメモリー量はcharacter setのサイズ（クラス数）に線形的に依存しています。Character setが大きいデータの場合（日本語、中国語など）、必要なメモリーが多すぎてNVIDIA V100などの普通のGPUにモデルが入らないです。\nこの研究ではメモリーのボトルネック（指定したcharacter sequenceの生成のための機能）をなくして、そしてその代わりにmulti-class conditional batch normalization（MCCBN)を提案しました。MCCBNを使うと、character setのサイズが変わっても、モデルのサイズはほぼ変わりません。\nいくつかの実験を行って、既存手法と比較しました。AMTを使ってhuman evaluationを行った結果、提案手法の生成画像は関連研究の手法より自然に見えることが判明しました。さらに、学習したモデルで生成した手書き文字の画像を手書き文字認識用のデータ拡張に使って、関連研究より高い認識の性能向上を達成しました。GANを用いた画像生成のタスクでよく使われている評価指標も使って、提案手法が既存手法より優れた性能を発揮していることが判明しました。結論として、提案手法のモデルは既存手法より必要なメモリー量が少なくて、尚、性能が既存手法より高いです。\n必要なメモリーの減少と効率化のおかげで、character setのサイズが多きい日本語のデータセットでも手書き文字画像生成のモデルを学習することができます。中国語や日本語の手書き文字画像生成（noiseからの生成）に関しては関連研究がなくて、私の研究は初の日本語手書き文字画像生成の試みです。\n","date":1619395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619395200,"objectID":"d53cd70b903d49ee3117386183900a24","permalink":"https://janzdenek.github.io/jokergan/","publishdate":"2021-04-26T00:00:00Z","relpermalink":"/jokergan/","section":"","summary":"現在、ACM Multimedia 2021で手書き文字の画像生成の論文が査読中です。この論文では手書き文字の画像生成のための新しい手法を提案しています。 手書き文","tags":null,"title":"JokerGAN","type":"page"},{"authors":["Jan Zdenek","Hideki Nakayama"],"categories":[],"content":"","date":1619177223,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619177223,"objectID":"0309c4faace5c9f9435b47600e0dfc54","permalink":"https://janzdenek.github.io/publication/jokergan/","publishdate":"2021-04-23T20:27:03+09:00","relpermalink":"/publication/jokergan/","section":"publication","summary":"Collecting labeled data for training of models for image recognition problems, including handwritten text recognition (HTR), is a tedious and expensive task. Recent work on handwritten text generation shows that generative models can be used as a data augmentation method to improve the performance of HTR systems. In this paper, we propose a new method for handwritten text generation that uses generative adversarial networks with multi-class conditional batch normalization, which enables us to use character sequences with variable lengths as conditional input for the generator. Compared to existing methods, our method has significantly lower memory requirements which are almost constant regardless of the size of the character set. This allows us to train a generative model for languages with a large number of characters, such as Japanese. We also introduce an additional condition that makes the generator aware whether there are characters extending below the baseline or above the mean line in the generated sequence, which helps generate handwritten text with well-aligned characters in the text line. Experiments on handwritten text datasets show that our proposed model can be used to boost the performance of HTR, particularly when we only have access to partially annotated data and train our generative model in semi-supervised fashion. The results also show that our model outperforms the current state-of-the-art for handwritten text generation. In addition, we perform a human evaluation study that indicates that the proposed method generates handwritten text images that look more realistic and natural.","tags":[],"title":"JokerGAN: Memory-Efficient Model for Handwritten Text Generation with Text Line Awareness","type":"publication"},{"authors":["Ryuichiro Hataya","Jan Zdenek","Kazuki Yoshizoe","Hideki Nakayama"],"categories":[],"content":"","date":1619177103,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619177103,"objectID":"6196c1fd3f731abe8c745db0ee159c00","permalink":"https://janzdenek.github.io/publication/madao_iccv/","publishdate":"2021-04-23T20:25:03+09:00","relpermalink":"/publication/madao_iccv/","section":"publication","summary":"Data augmentation policies drastically improve the performance of image recognition tasks, especially when the policies are optimized for the target data and tasks. In this paper, we propose to optimize image recognition models and data augmentation policies simultaneously to improve the performance using gradient descent. Unlike prior methods, our approach avoids using proxy tasks or reducing search space, and can directly improve the validation performance. Our method achieves efficient and scalable training by approximating the gradient of policies by implicit gradient with Neumann series approximation. We demonstrate that our approach can improve the performance of various image classification tasks, including ImageNet classification and fine-grained recognition, without using dataset-specific hyperparameter tuning.","tags":[],"title":"Meta Approach to Data Augmentation Optimization","type":"publication"},{"authors":["Jan Zdenek","Hideki Nakayama"],"categories":[],"content":"","date":1616927028,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616927028,"objectID":"febbbe08c4d7535ae27d086950ff0221","permalink":"https://janzdenek.github.io/publication/efficient-handwritten-text-generation/","publishdate":"2021-03-28T19:23:48+09:00","relpermalink":"/publication/efficient-handwritten-text-generation/","section":"publication","summary":"We propose a new method for handwritten text generation using generative adversarial networks with multi-class conditional batch normalization, which enables us to use character sequences with variable lengths as conditions for the generator. Compared to existing methods, our method converges faster and its memory requirements are similar regardless of the number of classes, which allows us to train a generative model for a language with a large number of characters, such as Japanese. We also introduce an additional condition that makes the generator aware whether there are characters extending below the baseline or above the mean line in the generated sequence, which helps generate results with well-aligned characters in the text line. Our human evaluation study shows that our proposed method generates handwritten text images that look more realistic and natural.","tags":[],"title":"Efficient Model for Handwritten Text Generation with Text Line Awareness","type":"publication"},{"authors":["Ryuichiro Hataya","Jan Zdenek","Kazuki Yoshizoe","Hideki Nakayama"],"categories":[],"content":"","date":1600946823,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600946823,"objectID":"9f9d97fb333519a91210384119e62f13","permalink":"https://janzdenek.github.io/publication/madao/","publishdate":"2020-09-24T20:27:03+09:00","relpermalink":"/publication/madao/","section":"publication","summary":"Data augmentation policies drastically improve the performance of image recognition tasks, especially when the policies are optimized for the target data and tasks. In this paper, we propose to optimize image recognition models and data augmentation policies simultaneously to improve the performance using gradient descent. Unlike prior methods, our approach avoids using proxy tasks or reducing search space, and can directly improve the validation performance. Our method achieves efficient and scalable training by approximating the gradient of policies by implicit gradient with Neumann series approximation. We demonstrate that our approach can improve the performance of various image classification tasks, including ImageNet classification and fine-grained recognition, without using dataset-specific hyperparameter tuning.","tags":[],"title":"MADAO: データ拡張最適化のためのメタ的アプローチ","type":"publication"},{"authors":["Ryuichiro Hataya","Jan Zdenek","Kazuki Yoshizoe","Hideki Nakayama"],"categories":[],"content":"","date":1600601223,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600601223,"objectID":"14ce11996a75d77eb2f256cb58cd4fed","permalink":"https://janzdenek.github.io/publication/faster-autoaugment/","publishdate":"2020-09-20T20:27:03+09:00","relpermalink":"/publication/faster-autoaugment/","section":"publication","summary":"Data augmentation methods are indispensable heuristics to boost the performance of deep neural networks, especially in image recognition tasks. Recently, several studies have shown that augmentation strategies found by search algorithms outperform hand-made strategies. Such methods employ black-box search algorithms over image transformations with continuous or discrete parameters and require a long time to obtain better strategies. In this paper, we propose a differentiable policy search pipeline for data augmentation, which is much faster than previous methods. We introduce approximate gradients for several transformation operations with discrete parameters as well as a differentiable mechanism for selecting operations. As the objective of training, we minimize the distance between the distributions of augmented and original data, which can be differentiated. We show that our method, Faster AutoAugment, achieves significantly faster searching than prior methods without a performance drop.","tags":[],"title":"Faster AutoAugment: Learning Augmentation Strategies using Backpropagation","type":"publication"},{"authors":["Jan Zdenek","Hideki Nakayama"],"categories":[],"content":"","date":1579932024,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579932024,"objectID":"749339d660a13a1c95d2f0c5b0131b5d","permalink":"https://janzdenek.github.io/publication/scene_text_erasing_weak_supervision/","publishdate":"2020-01-25T15:00:24+09:00","relpermalink":"/publication/scene_text_erasing_weak_supervision/","section":"publication","summary":"Scene text erasing is a task of removing text from natural scene images, which has been gaining attention in recent years. The main motivation is to conceal private information such as license plate numbers, and house nameplates that can appear in images. In this work, we propose a method for scene text erasing that approaches the problem as a general inpainting task. In contrast to previous methods, which require pairs of original images containing text and images from which the text has been removed, our method does not need corresponding image pairs for training. We use a separately trained scene text detector and an inpainting network. The scene text detector predicts segmentation maps of text instances which are then used as masks for the inpainting network. The network for inpainting, trained on a large-scale image dataset, fills in masked out regions in an input image and generates a final image in which the original text is no longer present. The results show that our method is able to successfully remove text and fill in the created holes to produce natural-looking images.","tags":[],"title":"Erasing Scene Text With Weak Supervision","type":"publication"},{"authors":["Ryuichiro Hataya","Jan Zdenek","Kazuki Yoshizoe","Hideki Nakayama"],"categories":[],"content":"","date":1574249223,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574249223,"objectID":"c0c96b0f4a3ebe04cc8cf5e34cdc0f33","permalink":"https://janzdenek.github.io/publication/faster-autoaugment_ibis/","publishdate":"2019-11-20T20:27:03+09:00","relpermalink":"/publication/faster-autoaugment_ibis/","section":"publication","summary":"","tags":[],"title":"Faster AutoAugment: Learning Augmentation Strategies using Backpropagation","type":"publication"},{"authors":["Jan Zdenek","Hideki Nakayama"],"categories":[],"content":"","date":1559989428,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559989428,"objectID":"b879f49a57548177f9086a8e7ba2793a","permalink":"https://janzdenek.github.io/publication/erasing-scene-text-using-a-general-inpainting-network/","publishdate":"2019-06-08T19:23:48+09:00","relpermalink":"/publication/erasing-scene-text-using-a-general-inpainting-network/","section":"publication","summary":"Scene text erasing is a task of removing text from natural scene images, which has been gaining attention in recent years. The main motivation is to conceal private information such as license plate numbers, and house name plates that can appear in images. In this work, we propose a novel method for scene text erasing that approaches the problem as a general inpainting task. Unlike previous methods, which require pairs of original images containing text and images with the text removed, our method does not need corresponding image pairs for training. We use a separately trained scene text detector and an inpainting network. The scene text detector predicts segmentation maps of text instances, which are then used as masks for the inpainting network. The network for inpainting, trained on the Places2 dataset of indoors and outdoors scenes, fills in masked out regions in an input image and generates a final image with erased text. The results show that our method is able to remove text from images and naturally fill in the background.","tags":[],"title":"Erasing Scene Text Using a General Inpainting Network","type":"publication"},{"authors":["Jan Zdenek","Hideki Nakayama"],"categories":[],"content":"","date":1510531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510531200,"objectID":"7dcc3771246cf2ae0a3940279cc957ec","permalink":"https://janzdenek.github.io/publication/bag-of-local-convolutional-triplets/","publishdate":"2019-06-08T19:22:29+09:00","relpermalink":"/publication/bag-of-local-convolutional-triplets/","section":"publication","summary":"The increasing interest in scene text reading in multilingual environments raises the need to recognize and distinguish between different writing systems. In this paper, we propose a novel method for script identification in scene text using triplets of local convolutional features in combination with the traditional bag-of-visual-words model. Feature triplets are created by making combinations of descriptors extracted from local patches of the input images using a convolutional neural network. This approach allows us to generate a more descriptive codeword dictionary for the bag-of-visual-words model, as the low discriminative power of weak descriptors is enhanced by other descriptors in a triplet. The proposed method is evaluated on two public benchmark datasets for scene text script identification and a public dataset for script identification in video captions. The experiments demonstrate that our method outperforms the baseline and yields competitive results on all three datasets.","tags":[],"title":"Bag of Local Convolutional Triplets for Script Identification in Scene Text","type":"publication"},{"authors":["Jan Zdenek","Hideki Nakayama"],"categories":[],"content":"","date":1495584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495584000,"objectID":"0b4dd5f274806d253d1ca070ea717025","permalink":"https://janzdenek.github.io/publication/script-identification-using-bag-of-words-with-entropy-weighted-patches/","publishdate":"2019-06-08T19:23:23+09:00","relpermalink":"/publication/script-identification-using-bag-of-words-with-entropy-weighted-patches/","section":"publication","summary":"The increasing interest in scene text reading in multilingual environments raises the need to recognize and distinguish between different writing systems. In this paper, we propose a novel method for script identification using convolutional features for the traditional bag-of-words model in a combination with weighting by means of intra-cluster information entropy. This approach exploits the expressive representation of convolutional neural networks, which have displayed outstanding performance in many text analysis and recognition tasks in recent years, discriminative power of script-characteristic features, and generalization abilities of bag-of-words model. The proposed method is evaluated on two public benchmark datasets for script identification. The experiments demonstrate that our method outperforms the baseline and yields competitive results.","tags":[],"title":"Script Identification Using Bag-of-Words with Entropy-weighted Patches","type":"publication"}]